{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6090932,"sourceType":"datasetVersion","datasetId":3486548},{"sourceId":6093388,"sourceType":"datasetVersion","datasetId":3486547},{"sourceId":6096424,"sourceType":"datasetVersion","datasetId":3491582},{"sourceId":6097804,"sourceType":"datasetVersion","datasetId":3492589},{"sourceId":6359419,"sourceType":"datasetVersion","datasetId":3663181},{"sourceId":6359436,"sourceType":"datasetVersion","datasetId":3495576},{"sourceId":6365199,"sourceType":"datasetVersion","datasetId":3486602}],"dockerImageVersionId":30498,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git config --global --unset https.proxy\n!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n!mkdir Model\n!mkdir -p Data/result","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:32:58.998942Z","iopub.execute_input":"2024-04-25T14:32:58.999208Z","iopub.status.idle":"2024-04-25T14:33:27.709721Z","shell.execute_reply.started":"2024-04-25T14:32:58.999184Z","shell.execute_reply":"2024-04-25T14:33:27.708426Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/DinhNam99/vffinder_retrain.git","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:34:05.596872Z","iopub.execute_input":"2024-04-25T14:34:05.597230Z","iopub.status.idle":"2024-04-25T14:34:07.088163Z","shell.execute_reply.started":"2024-04-25T14:34:05.597201Z","shell.execute_reply":"2024-04-25T14:34:07.087219Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'vffinder_retrain'...\nremote: Enumerating objects: 42, done.\u001b[K\nremote: Counting objects: 100% (42/42), done.\u001b[K\nremote: Compressing objects: 100% (35/35), done.\u001b[K\nremote: Total 42 (delta 12), reused 24 (delta 4), pack-reused 0\u001b[K\nReceiving objects: 100% (42/42), 2.92 MiB | 23.95 MiB/s, done.\nResolving deltas: 100% (12/12), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!python vffinder_retrain/Main_VULJIT_Detection.py \\\n--graph_dir='/kaggle/input/embedding-ast-changes/embedding_ast_changes'  \\\n--train_file='/kaggle/input/data-slient-fix/cross_train.txt' \\\n--test_file='/kaggle/input/data-slient-fix/cross_test.txt' \\\n--model_dir='/kaggle/working/Model' \\\n--max_epochs=50 \\\n--model_name='gat_v2' \\\n--mode='train_and_test'\\\n--hidden_size=32 \\\n--GNN_type=\"GAT_V2\"\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:42:03.907380Z","iopub.execute_input":"2024-04-25T14:42:03.907981Z","iopub.status.idle":"2024-04-25T17:06:19.514820Z","shell.execute_reply.started":"2024-04-25T14:42:03.907948Z","shell.execute_reply":"2024-04-25T17:06:19.513862Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\nTraining............\n\n30369\ndata size: 30369\nData(x=[48, 35], edge_index=[2, 41], edge_attr=[41, 3], edge_type=[41], y=[1])\nGATv2(\n  (gat1): GATv2Conv(35, 32, heads=8)\n  (gat2): GATv2Conv(256, 32, heads=1)\n  (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n  (lin): Linear(in_features=32, out_features=2, bias=True)\n)\nlearning rate :  1e-05\ncorrect: 19916\nepochs 1 train loss: 4.517124446481285 acc: 0.6558003226974876\ncorrect: 20088\nepochs 2 train loss: 2.317985315984878 acc: 0.6614639928874839\ncorrect: 20151\nepochs 3 train loss: 1.8408991751972092 acc: 0.6635384767361454\ncorrect: 20095\nepochs 4 train loss: 1.576549720112408 acc: 0.6616944910928908\ncorrect: 20208\nepochs 5 train loss: 1.405611440597849 acc: 0.6654153906944582\ncorrect: 20234\nepochs 6 train loss: 1.2794802217784262 acc: 0.6662715268859692\ncorrect: 20170\nepochs 7 train loss: 1.202040390683026 acc: 0.6641641147222497\ncorrect: 20446\nepochs 8 train loss: 1.0198094516180904 acc: 0.6732523296782904\ncorrect: 20470\nepochs 9 train loss: 0.9612373882305656 acc: 0.6740426092396852\ncorrect: 20581\nepochs 10 train loss: 0.8998999306128195 acc: 0.6776976522111363\ncorrect: 20626\nepochs 11 train loss: 0.830573530169778 acc: 0.6791794263887517\ncorrect: 20600\nepochs 12 train loss: 0.7400254555816496 acc: 0.6783232901972406\ncorrect: 20831\nepochs 13 train loss: 0.7053517697190895 acc: 0.685929730975666\ncorrect: 20907\nepochs 14 train loss: 0.665891560768338 acc: 0.688432282920083\ncorrect: 21004\nepochs 15 train loss: 0.6431457744884292 acc: 0.6916263294807204\ncorrect: 21105\nepochs 16 train loss: 0.6162825424724786 acc: 0.6949520893015905\ncorrect: 21114\nepochs 17 train loss: 0.5990000843198746 acc: 0.6952484441371135\ncorrect: 21144\nepochs 18 train loss: 0.5730277477691547 acc: 0.6962362935888571\ncorrect: 21129\nepochs 19 train loss: 0.5719575604792828 acc: 0.6957423688629852\ncorrect: 21069\nepochs 20 train loss: 0.5598229828141886 acc: 0.6937666699594982\ncorrect: 21128\nepochs 21 train loss: 0.5554859010091808 acc: 0.6957094405479272\ncorrect: 21118\nepochs 22 train loss: 0.5500032624562474 acc: 0.6953801573973459\ncorrect: 21158\nepochs 23 train loss: 0.5470337014401746 acc: 0.6966972899996707\ncorrect: 21180\nepochs 24 train loss: 0.5424802662560851 acc: 0.6974217129309493\ncorrect: 21195\nepochs 25 train loss: 0.5396607693057067 acc: 0.6979156376568211\ncorrect: 21163\nepochs 26 train loss: 0.5378001674740753 acc: 0.6968619315749613\ncorrect: 21136\nepochs 27 train loss: 0.5354111923578454 acc: 0.6959728670683921\ncorrect: 21216\nepochs 28 train loss: 0.531728713418597 acc: 0.6986071322730416\ncorrect: 21247\nepochs 29 train loss: 0.5325015880858036 acc: 0.6996279100398433\ncorrect: 21260\nepochs 30 train loss: 0.5263361393280079 acc: 0.7000559781355988\ncorrect: 21239\nepochs 31 train loss: 0.5212291922058362 acc: 0.6993644835193783\ncorrect: 21239\nepochs 32 train loss: 0.5215664947384425 acc: 0.6993644835193783\ncorrect: 21253\nepochs 33 train loss: 0.5165761320558916 acc: 0.699825479930192\ncorrect: 21319\nepochs 34 train loss: 0.5180826540644479 acc: 0.7019987487240278\ncorrect: 21326\nepochs 35 train loss: 0.5152969967301864 acc: 0.7022292469294347\ncorrect: 21367\nepochs 36 train loss: 0.5073285832298134 acc: 0.7035793078468174\ncorrect: 21448\nepochs 37 train loss: 0.5076353763726608 acc: 0.7062465013665251\ncorrect: 21399\nepochs 38 train loss: 0.5062845333881623 acc: 0.7046330139286773\ncorrect: 21473\nepochs 39 train loss: 0.5019729088311718 acc: 0.7070697092429781\ncorrect: 21524\nepochs 40 train loss: 0.49768214371684766 acc: 0.7087490533109421\ncorrect: 21527\nepochs 41 train loss: 0.496160799946801 acc: 0.7088478382561164\ncorrect: 21577\nepochs 42 train loss: 0.4966612272885728 acc: 0.7104942540090223\ncorrect: 21591\nepochs 43 train loss: 0.4959187997364429 acc: 0.710955250419836\ncorrect: 21618\nepochs 44 train loss: 0.49640656497680447 acc: 0.7118443149264052\ncorrect: 21622\nepochs 45 train loss: 0.492866489479703 acc: 0.7119760281866377\ncorrect: 21781\nepochs 46 train loss: 0.4845602563829998 acc: 0.7172116302808785\ncorrect: 21711\nepochs 47 train loss: 0.49261335701600034 acc: 0.7149066482268103\ncorrect: 21677\nepochs 48 train loss: 0.487097348500797 acc: 0.7137870855148342\ncorrect: 21757\nepochs 49 train loss: 0.4810537635785361 acc: 0.7164213507194837\n\nTesting..............\n\ndata size: 6001\nevaluate >\n81.44\nauc: 72.18 acc: 81.44 precision: 81.95 recall: 91.41 f1: 86.42 \nreport:\n              precision    recall  f1-score   support\n\n       clean       0.80      0.63      0.71      2123\n       buggy       0.82      0.91      0.86      3878\n\n    accuracy                           0.81      6001\n   macro avg       0.81      0.77      0.79      6001\nweighted avg       0.81      0.81      0.81      6001\n\nmatrix:\n[[1342  781]\n [ 333 3545]]\n","output_type":"stream"}]}]}